{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41fab3a9",
   "metadata": {},
   "source": [
    "# Name: Muhammad Sharjeel Akhtar\n",
    "# Roll No: P20-0101\n",
    "# Subject: Natural Language Processing (NLP)\n",
    "# Submitted To Respected Sir: Dr OMAR USMAN KHAN\n",
    "# Lab No: 04\n",
    "# Lab Title: Spacy Chatbot\n",
    "# ----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d53d11",
   "metadata": {},
   "source": [
    "# TASK NO 5: Finding Multiple Patterns automatically in Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ddd77434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"be7c9f64726b42b3b05132fadb0bfff1-0\" class=\"displacy\" width=\"800\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: blue; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">big</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">chased</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">everybody</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-be7c9f64726b42b3b05132fadb0bfff1-0-0\" stroke-width=\"2px\" d=\"M62,152.0 62,102.0 350.0,102.0 350.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-be7c9f64726b42b3b05132fadb0bfff1-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,154.0 L58,146.0 66,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-be7c9f64726b42b3b05132fadb0bfff1-0-1\" stroke-width=\"2px\" d=\"M212,152.0 212,127.0 347.0,127.0 347.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-be7c9f64726b42b3b05132fadb0bfff1-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M212,154.0 L208,146.0 216,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-be7c9f64726b42b3b05132fadb0bfff1-0-2\" stroke-width=\"2px\" d=\"M362,152.0 362,127.0 497.0,127.0 497.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-be7c9f64726b42b3b05132fadb0bfff1-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M362,154.0 L358,146.0 366,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-be7c9f64726b42b3b05132fadb0bfff1-0-3\" stroke-width=\"2px\" d=\"M512,152.0 512,127.0 647.0,127.0 647.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-be7c9f64726b42b3b05132fadb0bfff1-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M647.0,154.0 L651.0,146.0 643.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Sentence:  dog chased everybody\n",
      "Pattern Type:  SubRootObject\n",
      "Dependency: dog-nsubj\n",
      "Dependency: chased-ROOT\n",
      "Dependency: everybody-dobj\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern1 = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"ROOT\"}, {\"DEP\": \"dobj\"}]\n",
    "matcher.add(\"SubRootObject\", [pattern1])\n",
    "\n",
    "doc = nlp(\"The big dog chased everybody\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Optional: Display the dependency visualization\n",
    "displacy.render(doc, style='dep', options={'compact': True, 'color': 'blue'})\n",
    "\n",
    "# Print the matches\n",
    "for pattern_id, start, end in matches:\n",
    "    print(\"Matching Sentence: \", doc[start:end])\n",
    "    print(\"Pattern Type: \", doc.vocab.strings[pattern_id])\n",
    "    for token in doc[start:end]:\n",
    "        print(\"Dependency: {}-{}\".format(token, token.dep_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28767314",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"ROOT\"}, {\"OP\": \"*\"}, {\"DEP\": \"dobj\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567c9c7",
   "metadata": {},
   "source": [
    "# Attempt the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b179ce",
   "metadata": {},
   "source": [
    "# Question No 1 : What text and dependencies did the above code catch for the sentence “The big dog chased everybody”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a67456",
   "metadata": {},
   "source": [
    "# Answer No 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42e342bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Sentence:  dog chased everybody\n",
      "Pattern Type:  SubRootObject\n",
      "Dependency: dog-nsubj\n",
      "Dependency: chased-ROOT\n",
      "Dependency: everybody-dobj\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the English language model 'en_core_web_sm'\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define the SVO pattern\n",
    "pattern1 = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"ROOT\"}, {\"DEP\": \"dobj\"}]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"SubRootObject\", [pattern1])\n",
    "\n",
    "# Process the input sentence\n",
    "doc = nlp(\"The big dog chased everybody\")\n",
    "\n",
    "# Get matches using the matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Print the matched sentence and its dependencies\n",
    "for pattern_id, start, end in matches:\n",
    "    print(\"Matching Sentence: \", doc[start:end])\n",
    "    print(\"Pattern Type: \", doc.vocab.strings[pattern_id])\n",
    "    for token in doc[start:end]:\n",
    "        print(\"Dependency: {}-{}\".format(token, token.dep_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4645819",
   "metadata": {},
   "source": [
    "# Question No 2 : Change the sentence to “The big dog chased the cat”. Does the pattern catch the SVO pattern? If not,add another pattern2 to the matcher. The pattern should be DEP: nsubj, DEP: ROOT, DEP: det, DEP:dobj. When done, update matcher.add(\"SubRootDetObject\", [pattern2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31a015b",
   "metadata": {},
   "source": [
    "# Answer No 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b7b51cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Sentence:  dog chased the cat\n",
      "Pattern Type:  SubRootDetObject\n",
      "Dependency: dog-nsubj\n",
      "Dependency: chased-ROOT\n",
      "Dependency: the-det\n",
      "Dependency: cat-dobj\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the English language model 'en_core_web_sm'\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define the SVO pattern\n",
    "pattern1 = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"ROOT\"}, {\"DEP\": \"dobj\"}]\n",
    "\n",
    "# Add the SVO pattern to the matcher\n",
    "matcher.add(\"SubRootObject\", [pattern1])\n",
    "\n",
    "# Define pattern2 for DET + DOBJ\n",
    "pattern2 = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"ROOT\"}, {\"DEP\": \"det\", \"OP\": \"?\"}, {\"DEP\": \"dobj\"}]\n",
    "\n",
    "# Add pattern2 to the matcher\n",
    "matcher.add(\"SubRootDetObject\", [pattern2])\n",
    "\n",
    "# Process the modified sentence\n",
    "doc = nlp(\"The big dog chased the cat\")\n",
    "\n",
    "# Get matches using the updated matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Print the matched sentence and its dependencies\n",
    "for pattern_id, start, end in matches:\n",
    "    print(\"Matching Sentence: \", doc[start:end].text)\n",
    "    print(\"Pattern Type: \", doc.vocab.strings[pattern_id])\n",
    "    for token in doc[start:end]:\n",
    "        print(\"Dependency: {}-{}\".format(token, token.dep_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97bf70",
   "metadata": {},
   "source": [
    "# Question No 3 : Now design a third pattern for the sentence “The big dog chased the small cat”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7399d0",
   "metadata": {},
   "source": [
    "# Answer No 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4464fa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Sentence:  dog chased the cat\n",
      "Pattern Type:  SubRootDetObject\n",
      "Dependency: dog-nsubj\n",
      "Dependency: chased-ROOT\n",
      "Dependency: the-det\n",
      "Dependency: cat-dobj\n",
      "Matching Sentence:  dog chased the cat\n",
      "Pattern Type:  SubRootAmodDetObject\n",
      "Dependency: dog-nsubj\n",
      "Dependency: chased-ROOT\n",
      "Dependency: the-det\n",
      "Dependency: cat-dobj\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the English language model 'en_core_web_sm'\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Create a matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define the SVO pattern\n",
    "pattern1 = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"ROOT\"}, {\"DEP\": \"dobj\"}]\n",
    "\n",
    "# Add the SVO pattern to the matcher\n",
    "matcher.add(\"SubRootObject\", [pattern1])\n",
    "\n",
    "# Define pattern2 for DET + DOBJ\n",
    "pattern2 = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"ROOT\"}, {\"DEP\": \"det\", \"OP\": \"?\"}, {\"DEP\": \"dobj\"}]\n",
    "\n",
    "# Add pattern2 to the matcher\n",
    "matcher.add(\"SubRootDetObject\", [pattern2])\n",
    "\n",
    "# Define a new pattern3 for variations in the sentence structure\n",
    "pattern3 = [{\"DEP\": \"nsubj\"}, {\"DEP\": \"ROOT\"}, {\"DEP\": \"amod\", \"OP\": \"?\"}, {\"DEP\": \"det\", \"OP\": \"?\"}, {\"DEP\": \"dobj\"}]\n",
    "\n",
    "# Add pattern3 to the matcher with a unique name\n",
    "matcher.add(\"SubRootAmodDetObject\", [pattern3])\n",
    "\n",
    "\n",
    "# Process the modified sentence\n",
    "doc = nlp(\"The big dog chased the cat\")\n",
    "\n",
    "# Get matches using the updated matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Print the matched sentence and its dependencies\n",
    "for pattern_id, start, end in matches:\n",
    "    print(\"Matching Sentence: \", doc[start:end].text)\n",
    "    print(\"Pattern Type: \", doc.vocab.strings[pattern_id])\n",
    "    for token in doc[start:end]:\n",
    "        print(\"Dependency: {}-{}\".format(token, token.dep_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6e4ece",
   "metadata": {},
   "source": [
    "# To have clarity on what else is possible, visit https://spacy.io/api/matcher. Then, attempt the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e29f69",
   "metadata": {},
   "source": [
    "# Question No 1 : Design a pattern to identify a noun at least one time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5362d",
   "metadata": {},
   "source": [
    "# Answer No 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9a0a9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found: fox at position 3\n",
      "Match found: dog at position 8\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a matcher object\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define the pattern for nouns\n",
    "pattern2 = [{\"POS\": \"NOUN\"}]\n",
    "\n",
    "# Add the pattern to the matcher\n",
    "matcher.add(\"Noun\", [pattern2])\n",
    "\n",
    "# Process the text\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Find matches using the matcher\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Print the matched phrases and their positions\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]  # Get the matched span\n",
    "    print(f\"Match found: {span.text} at position {start}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ef3c51",
   "metadata": {},
   "source": [
    "# Question No 2 : Design a pattern to identify a noun of length >= 10 characters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c587c4f",
   "metadata": {},
   "source": [
    "# Answer No 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5dac85ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Phrase: hypnotherapist\n",
      "Pattern Type: LongNoun\n",
      "Matching Phrase: incantations\n",
      "Pattern Type: LongNoun\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern3 = [{\"POS\": \"NOUN\", \"LENGTH\": {\">=\": 10}}]\n",
    "matcher.add(\"LongNoun\", [pattern3])  # Use a descriptive label\n",
    "\n",
    "doc = nlp(\"The hypnotherapist's mesmerizing incantations calmed the agitated crowd.\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]  # Get the matched span\n",
    "    print(\"Matching Phrase:\", span.text)\n",
    "    print(\"Pattern Type:\", nlp.vocab.strings[match_id])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6153ffb",
   "metadata": {},
   "source": [
    "# Question No 3 : Design a pattern to identify vulgar language (Hint: you will need usage of IN, or NOT_IN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b9476",
   "metadata": {},
   "source": [
    "# Answer No 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a538a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match found: shit (Vulgar)\n",
      "Match found: hell (Vulgar)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a matcher object\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "# Define patterns for nouns and vulgar language\n",
    "\n",
    "vulgar_words = [\"shit\", \"bloody\", \"hell\"]  # Replace with your actual list\n",
    "pattern4 = [{\"LOWER\": {\"IN\": vulgar_words}}]\n",
    "\n",
    "# Add patterns to the matcher\n",
    "\n",
    "matcher.add(\"Vulgar\", [pattern4])\n",
    "\n",
    "# Process the new text\n",
    "text = \"The way you play football is shit, so stop playing with us and go to hell\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# Find matches\n",
    "matches = matcher(doc)\n",
    "\n",
    "# Print the matched phrases and their patterns\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]\n",
    "    pattern_string = nlp.vocab.strings[match_id]  # Get the pattern name\n",
    "    print(f\"Match found: {span.text} ({pattern_string})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44ef8b4",
   "metadata": {},
   "source": [
    "# TASK NO 6: Getting Replies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98cde3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Pizza ordering system\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def utterance(msg):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(msg)\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    \n",
    "    pattern1 = [{\"LEMMA\": {\"IN\": [\"salam\", \"assalam\", \"hi\", \"hello\"]}}]\n",
    "    matcher.add(\"greeting\", [pattern1])\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        print('Please rephrase your request. Be as specific as possible!')\n",
    "        return\n",
    "    \n",
    "    for pattern_id, start, end in matches:\n",
    "        if doc.vocab.strings[pattern_id] == \"greeting\":\n",
    "            print(\"Welcome to the Pizza ordering system\")\n",
    "            return\n",
    "\n",
    "# Example usage:\n",
    "utterance(\"Hello, I'd like to order a pizza.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ee492484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Pizza ordering system\n"
     ]
    }
   ],
   "source": [
    "msg = nlp(\"Hi\")\n",
    "utterance(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ee256",
   "metadata": {},
   "source": [
    "# Now attempt the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6c4b1",
   "metadata": {},
   "source": [
    "# Question No 1 : Extend the code by adding pattern and matches if a user enters: “I would like to order a pizza”. The bot should ask about which pizza type he/she wants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005e665",
   "metadata": {},
   "source": [
    "# Answer No 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3d6fe4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def utterance(msg):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(msg)\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    \n",
    "    # Greeting pattern\n",
    "    pattern_greeting = [{\"LEMMA\": {\"IN\": [\"salam\", \"assalam\", \"hi\", \"hello\"]}}]\n",
    "    matcher.add(\"greeting\", [pattern_greeting])\n",
    "    \n",
    "    # Menu pattern\n",
    "    pattern_menu = [{\"LOWER\": \"i\"}, {\"LOWER\": \"would\"}, {\"LOWER\": \"like\"}, {\"LOWER\": \"to\"}, {\"LOWER\": \"order\"}, {\"LOWER\": \"pizza\"}]\n",
    "    matcher.add(\"I would like to order pizza\", [pattern_menu])\n",
    "    \n",
    "    # Pizza order pattern\n",
    "    pattern_order = [{\"LOWER\": {\"IN\": [\"pizza\", \"pizzas\"]}}]\n",
    "    matcher.add(\"order\", [pattern_order])\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        return 'Please rephrase your request. Be as specific as possible!'\n",
    "    \n",
    "    for pattern_id, start, end in matches:\n",
    "        if doc.vocab.strings[pattern_id] == \"greeting\":\n",
    "            return \"Welcome to the Pizza ordering system!\"\n",
    "        \n",
    "        if doc.vocab.strings[pattern_id] == \"I would like to order pizza\":\n",
    "            return \"Our menu:\\n1. Margherita Pizza\\n2. Pepperoni Pizza\\n3. Veggie Pizza\"\n",
    "        \n",
    "        if doc.vocab.strings[pattern_id] == \"order\":\n",
    "            return \"Thank you for ordering! Your pizza will be prepared and delivered shortly.\"\n",
    "\n",
    "# Main interactive loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        bot_response = utterance(user_input)\n",
    "        print(\"Bot:\", bot_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc02c966",
   "metadata": {},
   "source": [
    "# Question No 2 :Extend the code by adding pattern and matches if a user enters: “I would like to complain about an order”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1994179",
   "metadata": {},
   "source": [
    "# Answer No 2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "189c6ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def utterance(msg):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(msg)\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    \n",
    "    # Greeting pattern\n",
    "    pattern_greeting = [{\"LEMMA\": {\"IN\": [\"salam\", \"assalam\", \"hi\", \"hello\"]}}]\n",
    "    matcher.add(\"greeting\", [pattern_greeting])\n",
    "    \n",
    "   # Menu pattern\n",
    "    pattern_menu = [{\"LOWER\": \"i\"}, {\"LOWER\": \"would\"}, {\"LOWER\": \"like\"}, {\"LOWER\": \"to\"}, {\"LOWER\": \"order\"}, {\"LOWER\": \"pizza\"}]\n",
    "    matcher.add(\"I would like to order pizza\", [pattern_menu])\n",
    "\n",
    "    # Pizza order pattern\n",
    "    pattern_order = [{\"LOWER\": {\"IN\": [\"pizza\", \"pizzas\"]}}]\n",
    "    matcher.add(\"order\", [pattern_order])\n",
    "    \n",
    "    # Complaint initiation pattern\n",
    "    pattern_complaint_initiate = [{\"LOWER\": \"i\"}, {\"LOWER\": \"would\"}, {\"LOWER\": \"like\"}, {\"LOWER\": \"to\"}, {\"LOWER\": \"complain\"}, {\"LOWER\": \"about\"}, {\"LOWER\": \"an\"}, {\"LOWER\": \"order\"}]\n",
    "    matcher.add(\"complaint_initiate\", [pattern_complaint_initiate])\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        return 'Please rephrase your request. Be as specific as possible!'\n",
    "    \n",
    "    for pattern_id, start, end in matches:\n",
    "        if doc.vocab.strings[pattern_id] == \"greeting\":\n",
    "            return \"Welcome to the Pizza ordering system!\"\n",
    "        \n",
    "        if doc.vocab.strings[pattern_id] == \"I would like to order pizza\":\n",
    "            return \"Our menu:\\n1. Margherita Pizza\\n2. Pepperoni Pizza\\n3. Veggie Pizza\"\n",
    "        \n",
    "        if doc.vocab.strings[pattern_id] == \"complaint_initiate\":\n",
    "            return handle_complaint()\n",
    "            \n",
    "        if doc.vocab.strings[pattern_id] == \"order\":\n",
    "            return \"Thank you for ordering! Your pizza will be prepared and delivered shortly.\"\n",
    "    return 'Please rephrase your request. Be as specific as possible!'\n",
    "\n",
    "def handle_complaint():\n",
    "    print(\"I'm sorry to hear that. Could you please specify the nature of your complaint?\")\n",
    "    complaint = input(\"You: \")\n",
    "    print(\"Thank you for bringing this to our attention. We apologize for any inconvenience.\")\n",
    "    print(\"We will ensure that this issue is addressed and won't happen again.\")\n",
    "    return 'Is there anything else I can help you with?'\n",
    "\n",
    "# Main interactive loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        bot_response = utterance(user_input)\n",
    "        print(\"Bot:\", bot_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b266e0d",
   "metadata": {},
   "source": [
    "# Question No 3 : In respone to what pizza type user wants, the user may want to enter “Chief Special Pizza”. Use the .lefts (mentioned in Lab 03) to get the pizza type. Ask about quantity. Use Cardinal as ent type to get the quantity, and place the order. Ask for address, and confirm the user with address."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26406ad3",
   "metadata": {},
   "source": [
    "# Answer No 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "08780d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You:  quit\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "def utterance(msg):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(msg)\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    \n",
    "    # Greeting pattern\n",
    "    pattern_greeting = [{\"LEMMA\": {\"IN\": [\"salam\", \"assalam\", \"hi\", \"hello\"]}}]\n",
    "    matcher.add(\"greeting\", [pattern_greeting])\n",
    "    \n",
    "    # Menu pattern\n",
    "    pattern_menu = [{\"LOWER\": \"i\"}, {\"LOWER\": \"would\"}, {\"LOWER\": \"like\"}, {\"LOWER\": \"to\"}, {\"LOWER\": \"order\"}, {\"LOWER\": \"pizza\"}]\n",
    "    matcher.add(\"I would like to order pizza\", [pattern_menu])\n",
    "    \n",
    "    # Complaint initiation pattern\n",
    "    pattern_complaint_initiate = [{\"LOWER\": \"i\"}, {\"LOWER\": \"would\"}, {\"LOWER\": \"like\"}, {\"LOWER\": \"to\"}, {\"LOWER\": \"complain\"}, {\"LOWER\": \"about\"}, {\"LOWER\": \"an\"}, {\"LOWER\": \"order\"}]\n",
    "    matcher.add(\"complaint_initiate\", [pattern_complaint_initiate])\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    if len(matches) == 0:\n",
    "        return 'Please rephrase your request. Be as specific as possible!'\n",
    "    \n",
    "    for pattern_id, start, end in matches:\n",
    "        if doc.vocab.strings[pattern_id] == \"greeting\":\n",
    "            return \"Welcome to the Pizza ordering system!\"\n",
    "        \n",
    "        if doc.vocab.strings[pattern_id] == \"I would like to order pizza\":\n",
    "            return handle_menu(doc)\n",
    "        \n",
    "        if doc.vocab.strings[pattern_id] == \"complaint_initiate\":\n",
    "            return handle_complaint()\n",
    "    \n",
    "    return 'Please rephrase your request. Be as specific as possible!'\n",
    "\n",
    "\n",
    "def handle_menu(doc):\n",
    "    print(\"Our menu:\")\n",
    "    print(\"1. Chicken Fajita Pizza\")\n",
    "    print(\"   Small: 520/-\")\n",
    "    print(\"   Medium: 1050/-\")\n",
    "    print(\"   Large: 1560/-\")\n",
    "    print(\"\\n2. Chicken Special Pizza\")\n",
    "    print(\"   Small: 520/-\")\n",
    "    print(\"   Medium: 1050/-\")\n",
    "    print(\"   Large: 1560/-\")\n",
    "    print(\"\\n3. Peri Peri Pizza\")\n",
    "    print(\"   Small: 520/-\")\n",
    "    print(\"   Medium: 1050/-\")\n",
    "    print(\"   Large: 1560/-\")\n",
    "    print(\"\\n4. Bon Fire Pizza\")\n",
    "    print(\"   Small: 520/-\")\n",
    "    print(\"   Medium: 1050/-\")\n",
    "    print(\"   Large: 1560/-\")\n",
    "    print(\"\\n5. Chicken Euro Pizza\")\n",
    "    print(\"   Small: 520/-\")\n",
    "    print(\"   Medium: 1050/-\")\n",
    "    print(\"   Large: 1560/-\")\n",
    "    print(\"\\n6. Chicken Tikka Pizza\")\n",
    "    print(\"   Small: 520/-\")\n",
    "    print(\"   Medium: 1050/-\")\n",
    "    print(\"   Large: 1560/-\")\n",
    "    print(\"\\n7. Cheese Lover Pizza\")\n",
    "    print(\"   Small: 520/-\")\n",
    "    print(\"   Medium: 1050/-\")\n",
    "    print(\"   Large: 1560/-\")\n",
    "    print(\"\\n8. Chicken Supreme Pizza\")\n",
    "    print(\"   Small: 520/-\")\n",
    "    print(\"   Medium: 1050/-\")\n",
    "    print(\"   Large: 1560/-\")\n",
    "    print(\"\\n9. Napoleon Pizza\")\n",
    "    print(\"   Medium: 1080/-\")\n",
    "    print(\"   Large: 1650/-\")\n",
    "    print(\"\\n10. Malai Boti Pizza\")\n",
    "    print(\"    Medium: 1080/-\")\n",
    "    print(\"    Large: 1650/-\")\n",
    "    print(\"\\n11. Behari Pizza\")\n",
    "    print(\"    Medium: 1180/-\")\n",
    "    print(\"    Large: 1680/-\")\n",
    "    print(\"\\n12. Kabab Stuffer Pizza\")\n",
    "    print(\"    Medium: 1250/-\")\n",
    "    print(\"    Large: 1820/-\")\n",
    "\n",
    "    order = input(\"You: \")\n",
    "    return handle_order(order)\n",
    "\n",
    "def handle_order(order):\n",
    "    # Extract pizza type using .lefts\n",
    "    pizza_type = order.lower()  # Assuming the order is the pizza type\n",
    "    print(f\"Great choice! You ordered a {pizza_type} pizza.\")\n",
    "    \n",
    "    # Ask for quantity\n",
    "    quantity = input(f\"How many {pizza_type} pizzas would you like to order? \")\n",
    "    print(f\"Confirm your order of {quantity} {pizza_type} pizzas.\")\n",
    "    \n",
    "    return handle_address()\n",
    "\n",
    "def handle_address():\n",
    "    # Ask for address\n",
    "    address = input(\"Please provide your delivery address: \")\n",
    "    print(f\"Thank you! Your order will be delivered to {address}. in 30 mins\")\n",
    "    return 'Is there anything else I can help you with?'\n",
    "\n",
    "def handle_complaint():\n",
    "    print(\"I'm sorry to hear that. Could you please specify the nature of your complaint?\")\n",
    "    complaint = input(\"You: \")\n",
    "    print(\"Thank you for bringing this to our attention. We apologize for any inconvenience.\")\n",
    "    print(\"We will ensure that this issue is addressed and won't happen again.\")\n",
    "    return 'Is there anything else I can help you with?'\n",
    "\n",
    "# Main interactive loop\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    if user_input.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        bot_response = utterance(user_input)\n",
    "        print(\"Bot:\", bot_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26fc188",
   "metadata": {},
   "source": [
    "# ENDING."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spaCy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
